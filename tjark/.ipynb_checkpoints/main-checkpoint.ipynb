{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-09T14:57:42.283342Z",
     "start_time": "2024-12-09T14:57:42.270111Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:57:45.744358Z",
     "start_time": "2024-12-09T14:57:42.363013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_csv(\"hf://datasets/newsmediabias/fake_news_elections_labelled_data/cleaned_fakenewsdata.csv\")"
   ],
   "id": "ec1962c377641cce",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:57:45.773948Z",
     "start_time": "2024-12-09T14:57:45.762242Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(5)",
   "id": "b5e1379dd0e65e15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text label\n",
       "0  \"\"\" Study in journal , Nature Communications :...  REAL\n",
       "1  \"\"\" Zelensky told the council that he was ther...  REAL\n",
       "2  \"\"\" Central bankers and bureaucrats are seizin...  REAL\n",
       "3  \"\"\" Last updated on .From the section Swimming...  REAL\n",
       "4  THE discussion in the Morning Star and elsewhe...  REAL"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\"\" Study in journal , Nature Communications :...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\"\" Zelensky told the council that he was ther...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"\"\" Central bankers and bureaucrats are seizin...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\"\" Last updated on .From the section Swimming...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE discussion in the Morning Star and elsewhe...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Data Preparation\n",
    "1. Split the data into training and testing sets\n",
    "2. Text Preprocessing (lowercase, remove special characters, remove stopwords, lemmatization, stemming)"
   ],
   "id": "fef54752c5438663"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:57:45.829089Z",
     "start_time": "2024-12-09T14:57:45.818337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "id": "1a7e1a45f3487a25",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tjarkgerken/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:57:45.908980Z",
     "start_time": "2024-12-09T14:57:45.895444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import re\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text"
   ],
   "id": "e00c440a1fce30b1",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Feature Extraction",
   "id": "cf189e10cc279ec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:58:07.293098Z",
     "start_time": "2024-12-09T14:58:07.251965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])"
   ],
   "id": "8953dc8ef7be952f",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_extraction\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CountVectorizer\n\u001B[1;32m      3\u001B[0m vectorizer \u001B[38;5;241m=\u001B[39m CountVectorizer()\n\u001B[1;32m      4\u001B[0m X \u001B[38;5;241m=\u001B[39m vectorizer\u001B[38;5;241m.\u001B[39mfit_transform(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcleaned_text\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'sklearn'"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ed99bca2afc6e180"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
